{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Transformer\n",
    "Here is the full transformer implemented in TensorFlow with example training loop (but no data). All the code is based on this (good) tutorial https://www.tensorflow.org/tutorials/text/transformer. The major modification is allowing multiple features to be embedded. Original paper https://arxiv.org/pdf/1706.03762.pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer model code\n",
    "### Masks and positional encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
    "    return pos * angle_rates\n",
    "\n",
    "#used to give transformer positional info\n",
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(np.arange(position)[:,np.newaxis],\n",
    "                           np.arange(d_model)[np.newaxis, :],\n",
    "                           d_model)\n",
    "    \n",
    "    # applt sin to even indices\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "    \n",
    "    #apply cos to odd indices in the array\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "    \n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "    \n",
    "    return tf.cast(pos_encoding, dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_2d_mask(seqs):\n",
    "    # We mask only those vectors of the sequence in which we have all zeroes \n",
    "    # (this is more scalable for some situations).\n",
    "    mask = tf.cast(tf.reduce_all(tf.math.equal(seqs, 0), axis=-1), tf.float32)\n",
    "    return mask[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n",
    "\n",
    "def create_look_ahead_mask(size):\n",
    "    # so the model cannot look ahead to future data\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size,size)), -1, 0) #lower triangular\n",
    "    #try changing -1 and 0 to make upper triangular\n",
    "    return mask # (seq_len, seq_len)\n",
    "\n",
    "def create_masks(inp, tar):\n",
    "    ''' create all masks needed for the transformer '''\n",
    "    \n",
    "    #encoder padding mask\n",
    "    enc_padding_mask = create_2d_mask(inp)\n",
    "    \n",
    "    #padding mask for encoder outputs in 2nd attention block in decoder\n",
    "    dec_padding_mask = create_2d_mask(inp)\n",
    "    \n",
    "    #used in the 1st attention block in the decoder\n",
    "    #to mask future tokens\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    combined_mask = tf.maximum(dec_padding_mask[..., 1:], look_ahead_mask)\n",
    "    \n",
    "    return enc_padding_mask, combined_mask, dec_padding_mask\n",
    "\n",
    "def create_loss_mask(inp):\n",
    "    ''' mask for the loss function '''\n",
    "    mask = tf.cast(tf.reduce_all(tf.math.equal(inp, 0), axis=-1), tf.float32)\n",
    "    return mask[:, 1:]  # (batch_size, seq_len - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding\n",
    "Embeddings for each feature which are then concatenated (alternatively could be added). Could incorporate continuous features with linear layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntityEmbedding(tf.keras.layers.Layer):\n",
    "    ''' embedding of multiple features'''\n",
    "    \n",
    "    def __init__(self, vocab_sizes, emb_dims):\n",
    "        super(EntityEmbedding, self).__init__()\n",
    "        assert len(vocab_sizes) == len(emb_dims) # check consistent\n",
    "        \n",
    "        self.emb_layers = [tf.keras.layers.Embedding(vocab, emb) for vocab, emb in zip(vocab_sizes, emb_dims)]\n",
    "        self.concat = tf.keras.layers.Concatenate(axis = -1)\n",
    "        \n",
    "    def call(self, x):\n",
    "        \n",
    "        x = self.concat([embedding(x[..., i]) for i, embedding in enumerate(self.emb_layers)])\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Â Multi-head attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    '''\n",
    "    q: query = (..., seq_len_q, depth)\n",
    "    k: key = (..., seq_len_k, depth)\n",
    "    v: value = (..., seq_len_v, depth_v)\n",
    "    mask: float tensor with shape broadcastable to\n",
    "        (..., seq_len_q, seq_len_k)\n",
    "        \n",
    "    must have seq_len_k == seq_len_v\n",
    "        \n",
    "    Returns:\n",
    "        output, attention_weights\n",
    "    '''\n",
    "    \n",
    "    # Q @ K^T\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b = True) # (..., seq_len_q, seq_len_k)\n",
    "    \n",
    "    # (Q @ K^T) / sqrt(d_k)\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "    \n",
    "    #mask\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)\n",
    "    \n",
    "    #softmax(.)\n",
    "    #(..., seq_len_q, seq_len_k)\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis = -1)\n",
    "    \n",
    "    #(Weights @ V)\n",
    "    output = tf.matmul(attention_weights, v) #(..., seq_len_q, depth_v_)\n",
    "    \n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        assert d_model % self.num_heads == 0\n",
    "        \n",
    "        self.depth = d_model // self.num_heads\n",
    "        \n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "    def split_heads(self, x, batch_size):\n",
    "        '''\n",
    "        Split the last dimension into (num_heads, depth).\n",
    "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "        \n",
    "        x : (batch_size, seq_len, d_model)\n",
    "        batch_size : int\n",
    "        \n",
    "        Returns:\n",
    "        x : (batch_size, num_heads, seq_len, depth)\n",
    "        '''\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm = [0, 2, 1, 3])\n",
    "    \n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "        \n",
    "        #linear\n",
    "        # (batch_size, seq_len, d_model)\n",
    "        q = self.wq(q)\n",
    "        k = self.wk(k)\n",
    "        v = self.wv(v)\n",
    "        \n",
    "        #split into heads\n",
    "        q = self.split_heads(q, batch_size) # (batch_size, num_heads, seq_len_q, depth)\n",
    "        k = self.split_heads(k, batch_size) # (batch_size, num_heads, seq_len_k, depth)\n",
    "        v = self.split_heads(v, batch_size) # (batch_size, num_heads, seq_len_v, depth)\n",
    "                \n",
    "        #Scaled Dot-Product Attention\n",
    "        # scaled_attention (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "            q, k, v, mask)\n",
    "        \n",
    "        # (batch, seq_len_q, num_heads, depth)\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm = [0, 2, 1, 3])\n",
    "        \n",
    "        #concat\n",
    "        # (batch_size, seq_len_q, d_model)\n",
    "        concat_attention = tf.reshape(scaled_attention, \n",
    "                                      (batch_size, -1, self.d_model))\n",
    "                                      \n",
    "        output = self.dense(concat_attention) # (batch_size, seq_len_q, d_model)\n",
    "                                      \n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder and Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    '''\n",
    "    A pointwise feed forward network is two fully connected\n",
    "    layers with a ReLU activation in between.\n",
    "    '''\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(dff, activation = 'relu'), # (batch_size, seq_len, dff)\n",
    "        tf.keras.layers.Dense(d_model) # (batch_size, seq_len, d_model)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate = 0.1):\n",
    "        '''\n",
    "        d_model = model dimension\n",
    "        num_heads = number of heads\n",
    "        dff = dimension of feed forward network\n",
    "        rate = dropout rate\n",
    "        '''    \n",
    "        super(EncoderLayer, self).__init__()\n",
    "        \n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "        \n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon = 1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon = 1e-6)\n",
    "        \n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "    def call(self, x, training, mask):\n",
    "        \n",
    "        attn_output, _ = self.mha(x, x, x, mask) # (bath_size, input_seq_len, d_model)\n",
    "        attn_output = self.dropout1(attn_output, training = training)\n",
    "        out1 = self.layernorm1(x + attn_output) # (batch_size, input_seq_len, d_model)\n",
    "        \n",
    "        ffn_output = self.ffn(out1) # (batch_size, input_seq_len, d_model)\n",
    "        ffn_output = self.dropout2(ffn_output, training = training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output) # (batch_size, input_seq_len, d_model)\n",
    "        \n",
    "        return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate = 0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        \n",
    "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "        \n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "        \n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon = 1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon = 1e-6)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon = 1e-6)\n",
    "        \n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "    def call(self, x, enc_output, training,\n",
    "            look_ahead_mask, padding_mask):\n",
    "        # enc_output shape == (batch_size, input_seq_len, d_model)\n",
    "        \n",
    "        attn1, _ = self.mha1(x, x, x, look_ahead_mask) # (batch_size, target_seq_len, d_model)\n",
    "        attn1 = self.dropout1(attn1, training = training)\n",
    "        out1 = self.layernorm1(attn1 + x)\n",
    "        \n",
    "        attn2, _ = self.mha2(enc_output, enc_output, out1, padding_mask) # (batch_size, target_seq_len, d_model)\n",
    "        attn2 = self.dropout2(attn2, training = training)\n",
    "        out2 = self.layernorm1(attn2 + out1) # (batch_size, target_seq_len, d_model)\n",
    "        \n",
    "        ffn_output = self.ffn(out2) # (batch_size, target_seq_len, d_model)\n",
    "        ffn_output = self.dropout3(ffn_output, training = training)\n",
    "        out3 = self.layernorm3(ffn_output + out2) # (batch_size, target_seq_len, d_model)\n",
    "        \n",
    "        return out3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, emb_dims, num_heads, dff, input_vocab_sizes,\n",
    "                 maximum_position_encoding, rate = 0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.d_model = np.sum(emb_dims)\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.embedding = EntityEmbedding(input_vocab_sizes, emb_dims)\n",
    "        \n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, self.d_model)\n",
    "        \n",
    "        self.enc_layers = [EncoderLayer(self.d_model, num_heads[i], dff, rate) for i in range(num_layers)]\n",
    "        \n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "    def call(self, x, training, mask):\n",
    "        \n",
    "        #x shape is batch_size x input_seq_len\n",
    "        \n",
    "        seq_len = tf.shape(x)[1]\n",
    "                \n",
    "        #adding embedding and position encoding\n",
    "        x = self.embedding(x) # (batch_size, input_seq_len, d_model)\n",
    "        \n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32)) # times by sqrt(d_model)\n",
    "        \n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "        \n",
    "        x = self.dropout(x, training = training)\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, training, mask)\n",
    "            \n",
    "        return x # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, emb_dims, num_heads, dff, target_vocab_sizes,\n",
    "                maximum_position_encoding, rate = 0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.d_model = np.sum(emb_dims)\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.embedding = EntityEmbedding(target_vocab_sizes, emb_dims)\n",
    "        \n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, self.d_model)\n",
    "        \n",
    "        self.dec_layers = [DecoderLayer(self.d_model, num_heads[i], dff, rate) for i in range(num_layers)]\n",
    "        \n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "        \n",
    "        seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {}\n",
    "        \n",
    "        x = self.embedding(x) # (batch_size, target_seq_len, d_model)\n",
    "        \n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "            \n",
    "        x = x + self.pos_encoding[:, :seq_len, :]\n",
    "        \n",
    "        x = self.dropout(x, training=training)\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            x = self.dec_layers[i](x, enc_output, training,\n",
    "                                   look_ahead_mask, padding_mask)\n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, num_layers, num_heads, dff,\n",
    "                 input_emb_dims, target_emb_dims,\n",
    "                 input_vocab_sizes, target_vocab_sizes,\n",
    "                 pe_input, pe_target, rate = 0.1):\n",
    "        \n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        assert np.sum(input_emb_dims) == np.sum(target_emb_dims)\n",
    "        d_model = np.sum(input_emb_dims)\n",
    "        \n",
    "        self.encoder = Encoder(num_layers, input_emb_dims, num_heads, dff,\n",
    "                               input_vocab_sizes, pe_input, rate)\n",
    "        \n",
    "        self.decoder = Decoder(num_layers, target_emb_dims, num_heads, dff,\n",
    "                              target_vocab_sizes, pe_target, rate)\n",
    "        \n",
    "        self.final_layer = tf.keras.layers.Dense(target_vocab_sizes[0])\n",
    "        \n",
    "    def call(self, inp, tar, training):\n",
    "        \n",
    "        enc_mask, look_ahead_mask, dec_mask = create_masks(inp, tar)\n",
    "        \n",
    "        enc_output = self.encoder(inp, training, enc_mask) # (batch_size, inp_seq_len, d_model)\n",
    "        \n",
    "        # (batch_size, tar_seq_len, d_model)\n",
    "        dec_output = self.decoder(tar, enc_output, training, look_ahead_mask, dec_mask)\n",
    "        \n",
    "        # (batch_size, tar_seq_len, target_vocab_size\n",
    "        final_output = self.final_layer(dec_output)\n",
    "        \n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "### Optimizer, loss and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    ''' Custom lr schedule. Recommended in paper. '''\n",
    "    \n",
    "    def __init__(self, lr_max, warmup_steps = 4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "        \n",
    "        self.lr_max = tf.cast(lr_max, tf.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "        \n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.sqrt(self.warmup_steps / step)\n",
    "        arg2 = step / self.warmup_steps\n",
    "        \n",
    "        return self.lr_max * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example lr schedule\n",
    "temp_lr_schedule = CustomSchedule(1.5e-3, warmup_steps = 2 * len(train_generator))\n",
    "plt.plot(temp_lr_schedule(tf.range(20 * len(train_generator), dtype = tf.float32)))\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.xlabel('Batches')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer\n",
    "lr_schedule = CustomSchedule(1.5e-3, warmup_steps = 2 * len(train_generator))\n",
    "optimizer = tf.keras.optimizers.Adam(lr_schedule, beta_1 = 0.9, beta_2 = 0.98, epsilon = 1e-9)\n",
    "\n",
    "#loss\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True, reduction = 'none')\n",
    "\n",
    "def loss_function(real, pred, mask):\n",
    "    ''' Masked version of the loss function'''\n",
    "        \n",
    "    loss_ = loss_object(real, pred)\n",
    "    mask = tf.cast(1 - mask, dtype = loss_.dtype) #want 1 to indicate not masked\n",
    "    loss_ *= mask\n",
    "    \n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n",
    "\n",
    "def accuracy_function(real, pred, mask):\n",
    "    ''' Masked version of the accuracy function'''\n",
    "    \n",
    "    accuracies = tf.equal(real, tf.argmax(pred, axis = -1))\n",
    "    accuracies = tf.cast(accuracies, dtype = tf.float32)\n",
    "    \n",
    "    mask = tf.cast(1 - mask, dtype = tf.float32) # 1 = not masked\n",
    "    accuracies *= mask\n",
    "    \n",
    "    return tf.reduce_sum(accuracies)/tf.reduce_sum(mask)\n",
    "\n",
    "#metrics\n",
    "train_loss = tf.keras.metrics.Mean()\n",
    "train_acc = tf.keras.metrics.Mean()\n",
    "val_acc = tf.keras.metrics.Mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_heads = [4, 4, 4]\n",
    "num_layers = len(num_heads)\n",
    "\n",
    "input_emb_dims = [34, 26, 20]\n",
    "target_emb_dims = [25, 25, 30]\n",
    "\n",
    "dff = 320\n",
    "rate = 0.075\n",
    "pe_input = 150 # > maxlen\n",
    "pe_target = 150\n",
    "\n",
    "#check consistent dimensions\n",
    "assert all([np.sum(input_emb_dims) % n == 0 for n in num_heads])\n",
    "assert all([np.sum(target_emb_dims) % n == 0 for n in num_heads])\n",
    "assert np.sum(input_emb_dims) == np.sum(target_emb_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define model\n",
    "transformer = Transformer(num_layers, num_heads, dff,\n",
    "                          input_emb_dims, target_emb_dims,\n",
    "                          input_vocab_sizes, target_vocab_sizes,\n",
    "                          pe_input, pe_target, rate = rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 40\n",
    "print_rate = 150 #rate of batches to print\n",
    "results = pd.DataFrame(columns = ['train_loss', 'train_acc', 'val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training loop\n",
    "for epoch in range(EPOCHS):\n",
    "            \n",
    "    start = time.time()\n",
    "    \n",
    "    # reset metrics\n",
    "    train_loss.reset_states()\n",
    "    train_acc.reset_states()\n",
    "    val_acc.reset_states()\n",
    "    \n",
    "    #train\n",
    "    for (batch, (x, y)) in enumerate(train_generator):\n",
    "        \n",
    "        # get data and mask\n",
    "        loss_mask = create_loss_mask(x)\n",
    "        y_inp, y_tar = y[:,:-1,:], y[:,1:,0]\n",
    "        \n",
    "        # forward pass and gradients\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = transformer(x, y_inp, training = True)\n",
    "            loss = loss_function(y_tar, predictions, loss_mask)\n",
    "        \n",
    "        # apply gradients\n",
    "        gradients = tape.gradient(loss, transformer.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "        \n",
    "        # update metrics\n",
    "        train_loss(loss)\n",
    "        train_acc(accuracy_function(y_tar, predictions, loss_mask))\n",
    "        \n",
    "        if batch % print_rate == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
    "                epoch + 1, batch, train_loss.result(), train_acc.result()))\n",
    "            \n",
    "    print('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
    "        epoch + 1, train_loss.result(), train_acc.result()))\n",
    "    \n",
    "    #validate\n",
    "    for (batch, (x, y)) in enumerate(val_generator):\n",
    "        \n",
    "        loss_mask = create_loss_mask(x)\n",
    "        y_inp, y_tar = y[:,:-1,:], y[:,1:,0]\n",
    "        \n",
    "        predictions = transformer(x, y_inp, training = False)\n",
    "        \n",
    "        val_acc(accuracy_function(y_tar, predictions, loss_mask))\n",
    "                \n",
    "    results = results.append({'train_loss' : train_loss.result().numpy(),\n",
    "                              'train_acc' : train_acc.result().numpy(),\n",
    "                              'val_acc' : val_acc.result().numpy()},\n",
    "                             ignore_index = True)\n",
    "    \n",
    "    print('Val Accuracy {:.4f}'.format(val_acc.result()))\n",
    "        \n",
    "    print('Time taken for 1 epoch: {:.4f} secs\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize = (20,20), nrows = 2, ncols = 2)\n",
    "ax[0,0].plot(results.train_loss)\n",
    "ax[0,0].title.set_text('Train Loss')\n",
    "\n",
    "ax[1,0].plot(results.train_acc)\n",
    "ax[1,0].title.set_text('Train Accuracy')\n",
    "\n",
    "ax[1,1].plot(results.val_acc)\n",
    "ax[1,1].title.set_text('Val Accuracy')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
